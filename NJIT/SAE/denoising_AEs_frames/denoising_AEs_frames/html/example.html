
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>example</title><meta name="generator" content="MATLAB 8.2"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2019-06-26"><meta name="DC.source" content="example.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, tt, code { font-size:12px; }
pre { margin:0px 0px 20px; }
pre.error { color:red; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#2">Dedication</a></li><li><a href="#4">Build your dataset by loading your images</a></li><li><a href="#5">load training data</a></li><li><a href="#7">load testing data</a></li><li><a href="#9">Initialization of the Algorithm</a></li><li><a href="#10">Train and test</a></li><li><a href="#12">Important Note:</a></li><li><a href="#14">Illustration</a></li><li><a href="#15">Referances</a></li></ul></div><p><img vspace="5" hspace="5" src="DEN.PNG" alt=""> </p><pre class="codeinput">clear <span class="string">all</span>
clc
</pre><h2>Dedication<a name="2"></a></h2><pre>This Work is dedicated to my son "BERGHOUT Loukmane".</pre><h2>Build your dataset by loading your images<a name="4"></a></h2><h2>load training data<a name="5"></a></h2><pre>In the folder directory there is a folder named 'Train', after a
dialogue box appears, choose  that folder and click choose.</pre><pre class="codeinput">pathname        = uigetdir;
allfiles        = dir(fullfile(pathname,<span class="string">'*.jpg'</span>));
xtr=[];       <span class="comment">% initialize training inputs</span>
gamma=[96 97];<span class="comment">% size of each image</span>
<span class="keyword">for</span> i=1:size(allfiles,1)
x=imread([pathname <span class="string">'\\'</span> allfiles(i).name]);
x=imresize(x,gamma);
x=rgb2gray(x);
x=double(x);
xtr=[xtr; x];<span class="comment">% training set building</span>
<span class="keyword">end</span>
</pre><h2>load testing data<a name="7"></a></h2><pre>In the folder directory there is a folder named 'Test', after a
dialogue box appears, choose  that folder and click choose.</pre><pre class="codeinput">pathname        = uigetdir;
allfiles        = dir(fullfile(pathname,<span class="string">'*.jpg'</span>));
xts=[];         <span class="comment">% initialize testing inputs</span>
<span class="keyword">for</span> i=1:size(allfiles,1)
x=imread([pathname <span class="string">'\\'</span> allfiles(i).name]);
x=imresize(x,gamma);
x=rgb2gray(x);
x=double(x);
xts=[xts; x];<span class="comment">% testing set building</span>
<span class="keyword">end</span>
</pre><h2>Initialization of the Algorithm<a name="9"></a></h2><pre class="codeinput">NumberofHiddenNeurons=500;  <span class="comment">% number of neurons</span>
D_ratio=0.35;               <span class="comment">% the ratio of noise in each chosen frame</span>
DB=1;                       <span class="comment">% the power of white gaussian noise in decibels</span>
ActivationFunction=<span class="string">'sig'</span>;   <span class="comment">% Activation function</span>
frame=20;                   <span class="comment">% size of each frame</span>
</pre><h2>Train and test<a name="10"></a></h2><pre>During training, gaussian white noise and zeros will be added to
randomly chosen frames .
The Autoencoder will be trained to avoide this type of data corruption.</pre><pre class="codeinput">[AE_net]=elm_AE(xtr,xts,NumberofHiddenNeurons,ActivationFunction,D_ratio,DB,frame)
</pre><pre class="codeoutput">
AE_net = 

          x: [97x6624 double]
    Ytr_hat: [97x6624 double]
    Yts_hat: [97x768 double]
    Tr_Time: 2.7924
    Ts_Time: 0.0312
     Tr_acc: 0.0778
     Ts_acc: 3.7265e-14
       beta: [500x97 double]

</pre><h2>Important Note:<a name="12"></a></h2><pre>After completing the training process,we will no longer in need  To use
InputWeight for mapping the inputs to the hidden layer, and  instead of
that we will use the Outputweights beta  for coding and decoding phases
and also we can't use the activation  functon because  beta  is coputed
after the activation .
The same thing is applied on biases (please for more details check the
function'ELM_AE' at the testing phase).</pre><h2>Illustration<a name="14"></a></h2><pre class="codeinput">subplot(121)
corrupted=AE_net.x(:,1:gamma(2)*2);
imshow(corrupted')
title(<span class="string">'corrupted images '</span>);
subplot(122)
regenerated=AE_net.Ytr_hat(:,1:gamma(2)*2);
imagesc(regenerated'), colormap(<span class="string">'gray'</span>);
title(<span class="string">'regenerated images'</span>);
</pre><img vspace="5" hspace="5" src="example_01.png" alt=""> <h2>Referances<a name="15"></a></h2><pre>[1]	P. Vincent, H. Larochelle, I. Lajoie, Y. Bengio, and P.-A. Manzagol, &#8220;Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion,&#8221; J. Mach. Learn. Res., vol. 11, no. 3, pp. 3371&#8211;3408, 2010.
[2]	L. le Cao, W. bing Huang, and F. chun Sun, &#8220;Building feature space of extreme learning machine with sparse denoising stacked-autoencoder,&#8221; Neurocomputing, vol. 174, pp. 60&#8211;71, 2016.
[3]	G. Bin Huang, &#8220;What are Extreme Learning Machines? Filling the Gap Between Frank Rosenblatt&#8217;s Dream and John von Neumann&#8217;s Puzzle,&#8221; Cognit. Comput., vol. 7, no. 3, pp. 263&#8211;278, 2015.</pre><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2013b</a><br></p></div><!--
##### SOURCE BEGIN #####
%%
% 
% <<DEN.PNG>>
% 

clear all
clc 
%% Dedication
%%
% 
%  This Work is dedicated to my son "BERGHOUT Loukmane".
%% Build your dataset by loading your images
%% load training data
%%
% 
%  In the folder directory there is a folder named 'Train', after a 
%  dialogue box appears, choose  that folder and click choose.  

pathname        = uigetdir;
allfiles        = dir(fullfile(pathname,'*.jpg'));
xtr=[];       % initialize training inputs
gamma=[96 97];% size of each image
for i=1:size(allfiles,1)    
x=imread([pathname '\\' allfiles(i).name]);
x=imresize(x,gamma);
x=rgb2gray(x);
x=double(x);
xtr=[xtr; x];% training set building
end
%% load testing data 
%%
% 
%  In the folder directory there is a folder named 'Test', after a 
%  dialogue box appears, choose  that folder and click choose.  

pathname        = uigetdir;
allfiles        = dir(fullfile(pathname,'*.jpg'));
xts=[];         % initialize testing inputs
for i=1:size(allfiles,1)    
x=imread([pathname '\\' allfiles(i).name]);
x=imresize(x,gamma);
x=rgb2gray(x);
x=double(x);
xts=[xts; x];% testing set building
end

%% Initialization of the Algorithm
NumberofHiddenNeurons=500;  % number of neurons
D_ratio=0.35;               % the ratio of noise in each chosen frame
DB=1;                       % the power of white gaussian noise in decibels 
ActivationFunction='sig';   % Activation function
frame=20;                   % size of each frame
%% Train and test
%%
% 
%  During training, gaussian white noise and zeros will be added to 
%  randomly chosen frames .
%  The Autoencoder will be trained to avoide this type of data corruption.

[AE_net]=elm_AE(xtr,xts,NumberofHiddenNeurons,ActivationFunction,D_ratio,DB,frame)
%% Important Note: 
%%
% 
%  After completing the training process,we will no longer in need  To use 
%  InputWeight for mapping the inputs to the hidden layer, and  instead of 
%  that we will use the Outputweights beta  for coding and decoding phases
%  and also we can't use the activation  functon because  beta  is coputed 
%  after the activation .
%  The same thing is applied on biases (please for more details check the 
%  function'ELM_AE' at the testing phase).

%% Illustration
subplot(121)
corrupted=AE_net.x(:,1:gamma(2)*2);
imshow(corrupted')
title('corrupted images ');
subplot(122)
regenerated=AE_net.Ytr_hat(:,1:gamma(2)*2);
imagesc(regenerated'), colormap('gray');
title('regenerated images');
%% Referances
%%
%  [1]	P. Vincent, H. Larochelle, I. Lajoie, Y. Bengio, and P.-A. Manzagol, “Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion,” J. Mach. Learn. Res., vol. 11, no. 3, pp. 3371–3408, 2010.
%  [2]	L. le Cao, W. bing Huang, and F. chun Sun, “Building feature space of extreme learning machine with sparse denoising stacked-autoencoder,” Neurocomputing, vol. 174, pp. 60–71, 2016.
%  [3]	G. Bin Huang, “What are Extreme Learning Machines? Filling the Gap Between Frank Rosenblatt’s Dream and John von Neumann’s Puzzle,” Cognit. Comput., vol. 7, no. 3, pp. 263–278, 2015.
%  






##### SOURCE END #####
--></body></html>